# Extreme Fault Injection Configuration
# This configuration stress tests the observability stack with all fault types simultaneously
# Uses aggressive parameters to validate system behavior under severe degradation

# Mode: mock (fault injection works with mock providers)
mode: mock

# Agent configuration
agent:
  agent_id: canary_fault_extreme_001
  agent_name: Extreme Fault Canary

# Mock provider base settings
mock_settings:
  # Base settings (all overridden by fault injection profiles)
  llm_latency_ms: 500
  tool_latency_ms: 200
  tool_failure_rate: 0.0

# Fault injection configuration
fault_injection:
  # Enable fault injection
  enabled: true
  
  # ALL fault profiles active simultaneously for maximum stress testing
  profiles:
    - high_latency
    - intermittent_failures
    - rate_limits
    - token_limits
    - partial_responses
  
  # High latency profile - EXTREME delays
  high_latency:
    llm_latency_ms: 10000   # 10 seconds per LLM call
    tool_latency_ms: 8000   # 8 seconds per tool call
  
  # Intermittent failures profile - HIGH failure rates
  intermittent_failures:
    llm_failure_rate: 0.4    # 40% of LLM calls fail
    tool_failure_rate: 0.5   # 50% of tool calls fail
    failure_pattern: "burst" # Clustered failures for maximum impact
  
  # Rate limits profile - AGGRESSIVE rate limiting
  rate_limits:
    # Trigger rate limiting after only 2 calls
    trigger_after_calls: 2
  
  # Token limits profile - LOW token limits
  token_limits:
    max_tokens: 500      # Very low token limit
    exceed_by: 200       # Exceed by 200 tokens to trigger errors
  
  # Partial responses profile - INCOMPLETE responses
  partial_responses:
    completeness_ratio: 0.5  # Only 50% of response returned

# OpenTelemetry configuration
otlp:
  # OTLP collector endpoint
  endpoint: http://localhost:4317
  insecure: true

# Scenarios to execute
# WARNING: Many scenarios may fail due to extreme fault conditions
# This is expected - the goal is to validate telemetry capture under failure
scenarios:
  - simple_tool_call      # Likely to fail due to compound faults
  - multi_tool_chain      # Very likely to fail with multiple fault points
  - tool_failure          # Guaranteed failures with extreme conditions
  - high_token_usage      # Will trigger token limit errors
  - conversation_context  # Tests recovery across multiple failing turns
  - multi_agent          # Tests fault propagation in worst-case scenarios

# Telemetry validation
# Validates that even under extreme failure, telemetry is captured correctly
validation:
  prometheus_url: http://localhost:9090
  opensearch_url: https://localhost:9200
  opensearch_user: admin
  opensearch_password: ${OPENSEARCH_PASSWORD}

# About Extreme Fault Testing:
#
# This configuration is designed for STRESS TESTING the observability stack.
# It combines ALL fault types with AGGRESSIVE parameters:
#
# 1. High Latency: 10s LLM + 8s tool delays = extremely slow
# 2. Intermittent Failures: 40-50% failure rates in burst pattern
# 3. Rate Limits: Triggered after only 2 calls
# 4. Token Limits: Low 500 token limit, frequently exceeded
# 5. Partial Responses: Only 50% of responses returned
#
# Expected Outcomes:
# - Most scenarios will FAIL (this is intentional)
# - The goal is NOT to have passing scenarios
# - The goal IS to validate that:
#   * Error telemetry is captured correctly
#   * Spans show proper error attributes
#   * Metrics reflect the degraded state
#   * Logs contain detailed error information
#   * The system doesn't crash or hang
#
# Use Cases:
# - Validate observability under catastrophic failure
# - Test error handling and recovery mechanisms
# - Verify telemetry completeness during outages
# - Stress test the ATLAS stack itself
# - Validate alerting thresholds and SLOs
#
# WARNING: This configuration will generate significant error telemetry.
# Do not run continuously - use only for periodic stress testing.
