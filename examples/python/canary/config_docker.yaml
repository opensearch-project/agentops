# Docker/Container Configuration - Comprehensive Multi-Agent Canary with Fault Injection
# This configuration is optimized for running the canary inside Docker Compose
# Uses service names instead of localhost for inter-container communication
#
# Features:
# - Three-level agent hierarchy (grandparent → parent → children)
# - Mixed span kinds (INTERNAL and CLIENT) across hierarchy
# - Compound fault injection (latency + failures + rate limits)
# - Comprehensive scenario coverage
# - Full telemetry validation under degraded conditions
#
# This configuration provides a realistic stress test of the observability stack
# with complex agent interactions and multiple simultaneous fault types.

# Mode: mock (fault injection works with mock providers)
mode: mock

# Three-level multi-agent hierarchy with mixed span kinds
# Grandparent → Parent → Two Children (one INTERNAL, one CLIENT)
agent:
  agent_id: docker_grandparent_001
  agent_name: Docker Grandparent Agent
  span_kind: INTERNAL  # Top-level agent uses INTERNAL
  description: Top-level orchestrator agent
  
  # Grandparent has one child: the parent agent
  children:
    # Parent agent (middle level) with CLIENT span kind
    - agent_id: docker_parent_001
      agent_name: Docker Parent Agent
      span_kind: CLIENT  # Middle-level uses CLIENT to simulate remote service
      description: Middle-level coordinator agent (remote service pattern)
      
      # Parent has two children with different span kinds
      children:
        # Child 1: INTERNAL span kind
        # Simulates in-process agent invocation pattern
        - agent_id: docker_child_internal_001
          agent_name: Docker Internal Child
          span_kind: INTERNAL
          description: In-process child agent (LangChain/CrewAI pattern)
        
        # Child 2: CLIENT span kind
        # Simulates remote agent service invocation pattern
        - agent_id: docker_child_client_001
          agent_name: Docker Client Child
          span_kind: CLIENT
          description: Remote service child agent (OpenAI Assistants/Bedrock pattern)

# Mock provider base settings
mock_settings:
  # Base settings (overridden by fault injection profiles)
  llm_latency_ms: 500
  tool_latency_ms: 200
  tool_failure_rate: 0.0

# Compound fault injection configuration
# Tests observability stack with multiple simultaneous fault types
# Simulates realistic degraded production scenarios
fault_injection:
  # Enable fault injection
  enabled: true
  
  # Active fault profiles - compound failures for comprehensive testing
  profiles:
    - high_latency
    - intermittent_failures
    - rate_limits
  
  # High latency profile
  # Simulates slow API responses across all agents
  high_latency:
    llm_latency_ms: 3000   # 3 seconds
    tool_latency_ms: 2000  # 2 seconds
  
  # Intermittent failures profile
  # Simulates unreliable APIs with moderate failure rates
  intermittent_failures:
    llm_failure_rate: 0.15   # 15% failure rate
    tool_failure_rate: 0.20  # 20% failure rate
    failure_pattern: "random"
  
  # Rate limits profile
  # Simulates API rate limiting (HTTP 429 errors)
  rate_limits:
    # Trigger rate limiting after 5 calls
    trigger_after_calls: 5

# OpenTelemetry configuration
otlp:
  # OTLP collector endpoint - use service name in Docker
  endpoint: http://otel-collector:4317
  
  # Whether to use insecure connection (true for development)
  insecure: true

# Scenarios to execute (in order)
# Comprehensive coverage of all scenario types with compound fault injection
scenarios:
  - simple_tool_call      # Single tool invocation with compound faults
  - multi_tool_chain      # Multiple sequential tool calls with cumulative faults
  - tool_failure          # Explicit failure testing (triple-fault scenario)
  - high_token_usage      # Large input/output with faults
  - conversation_context  # Multi-turn conversation with fault recovery
  - multi_agent          # Three-level agent hierarchy with fault propagation

# Telemetry validation
# Validates that telemetry appears correctly in Prometheus and OpenSearch
# even under compound fault conditions
validation:
  # Prometheus URL for metrics validation
  prometheus_url: http://prometheus:9090
  
  # OpenSearch URL for traces/logs validation
  opensearch_url: https://opensearch:9200
  
  # OpenSearch credentials
  opensearch_user: admin
  opensearch_password: ${OPENSEARCH_PASSWORD}

# About This Configuration:
# =========================
#
# This comprehensive canary configuration tests:
#
# 1. Three-Level Multi-Agent Hierarchy:
#    - Grandparent agent (INTERNAL) at top level
#    - Parent agent (CLIENT) at middle level
#    - Two child agents (INTERNAL and CLIENT) at leaf level
#    - Trace context propagation across three levels
#    - Mixed span kinds throughout hierarchy
#    - Unique agent IDs and conversation ID continuity
#
# 2. Compound Fault Injection:
#    - High latency (3s LLM, 2s tools) on every call
#    - Intermittent failures (15-20% failure rates)
#    - Rate limiting after 5 calls
#    - Compound fault effects across all scenarios
#    - Fault propagation through three-level hierarchy
#
# 3. Comprehensive Scenarios:
#    - All scenario types from simple to complex
#    - Multi-turn conversations with context
#    - High token usage patterns
#    - Explicit failure testing
#    - Multi-agent orchestration with deep nesting
#
# 4. Telemetry Validation:
#    - Metrics in Prometheus under degraded conditions
#    - Traces in OpenSearch with deep hierarchies
#    - Gen-AI semantic conventions across all agents
#    - Span hierarchy correctness with three levels
#    - Error propagation and attribution
#
# Expected Trace Structure:
# =========================
# Trace ID: <shared across all agents>
# │
# ├─ Span: invoke_agent Grandparent (kind: INTERNAL)
# │  │ gen_ai.agent.id: "docker_grandparent_001"
# │  │
# │  └─ Span: invoke_agent Parent (kind: CLIENT)
# │     │ gen_ai.agent.id: "docker_parent_001"
# │     │
# │     ├─ Span: invoke_agent Internal Child (kind: INTERNAL)
# │     │  │ gen_ai.agent.id: "docker_child_internal_001"
# │     │  └─ Span: execute_tool (with faults)
# │     │
# │     └─ Span: invoke_agent Client Child (kind: CLIENT)
# │        │ gen_ai.agent.id: "docker_child_client_001"
# │        └─ Span: execute_tool (with faults)
#
# Expected Behavior:
# ==================
# - Many operations will fail due to compound fault injection (expected)
# - All telemetry should be captured correctly despite failures
# - Span hierarchies should be preserved across three levels
# - Error spans should have proper status codes and exception details
# - Metrics should reflect both successful and failed operations
# - Rate limiting should trigger after 5 calls
# - Latency should be consistently high (3s+ for LLM calls)
# - Failure rates should be approximately 15-20%
#
# This configuration provides the most comprehensive test of the observability
# stack's ability to handle complex multi-agent interactions under realistic
# degraded conditions with multiple simultaneous fault types.
